{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D,GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "\n",
    "import os\n",
    "os.chdir('./4-2/')\n",
    "import kt_utils\n",
    "\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes = kt_utils.load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "X_train.shape = (600, 64, 64, 3)\nY_train.shape = (600, 1)\nX_test.shape = (150, 64, 64, 3)\nY_test.shape = (150, 1)\n"
    }
   ],
   "source": [
    "X_train = train_set_x_orig / 255.\n",
    "X_test = test_set_x_orig / 255.\n",
    "Y_train = train_set_y_orig.T\n",
    "Y_test = test_set_y_orig.T\n",
    "print(f'X_train.shape = {X_train.shape}')\n",
    "print(f'Y_train.shape = {Y_train.shape}')\n",
    "print(f'X_test.shape = {X_test.shape}')\n",
    "print(f'Y_test.shape = {Y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HappyModel(input_shape):\n",
    "\n",
    "    '''\n",
    "    input_shape -  A shape tuple (integer), not including the batch size.\n",
    "        For instance, `shape=(32,)` indicates that the expected input\n",
    "        will be batches of 32-dimensional vectors.\n",
    "    '''\n",
    "    \n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "    \n",
    "    X = Conv2D(32, (7, 7), strides=(1, 1), name='conv0')(X)\n",
    "    X = BatchNormalization(axis=3, name='bn0')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    X = MaxPooling2D((2, 2), name='max_pool')(X)\n",
    "\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(1, activation='sigmoid', name='fc')(X)\n",
    "\n",
    "    model = Model(inputs=X_input, outputs=X, name='HappyModel')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "WARNING:tensorflow:From C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n\nWARNING:tensorflow:From C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n\nWARNING:tensorflow:From C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n\nWARNING:tensorflow:From C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n\nWARNING:tensorflow:From C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n\nWARNING:tensorflow:From C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n\nWARNING:tensorflow:From C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n\nWARNING:tensorflow:From C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n\nWARNING:tensorflow:From C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.where in 2.0, which has the same broadcast rule as np.where\nEpoch 1/40\n600/600 [==============================] - 8s 14ms/step - loss: 3.3841 - acc: 0.4833\nEpoch 2/40\n600/600 [==============================] - 8s 13ms/step - loss: 0.9763 - acc: 0.7033\nEpoch 3/40\n600/600 [==============================] - 8s 13ms/step - loss: 0.5903 - acc: 0.7950\nEpoch 4/40\n600/600 [==============================] - 7s 12ms/step - loss: 0.2383 - acc: 0.8933\nEpoch 5/40\n600/600 [==============================] - 7s 12ms/step - loss: 0.1771 - acc: 0.9283\nEpoch 6/40\n600/600 [==============================] - 7s 12ms/step - loss: 0.1340 - acc: 0.9500\nEpoch 7/40\n600/600 [==============================] - 7s 12ms/step - loss: 0.1342 - acc: 0.9483\nEpoch 8/40\n600/600 [==============================] - 7s 12ms/step - loss: 0.1056 - acc: 0.9750\nEpoch 9/40\n600/600 [==============================] - 7s 12ms/step - loss: 0.0988 - acc: 0.9700\nEpoch 10/40\n600/600 [==============================] - 7s 12ms/step - loss: 0.0895 - acc: 0.9817\nEpoch 11/40\n600/600 [==============================] - 7s 12ms/step - loss: 0.0906 - acc: 0.9700\nEpoch 12/40\n600/600 [==============================] - 7s 12ms/step - loss: 0.0901 - acc: 0.9783\nEpoch 13/40\n600/600 [==============================] - 7s 12ms/step - loss: 0.0827 - acc: 0.9767\nEpoch 14/40\n600/600 [==============================] - 7s 12ms/step - loss: 0.0721 - acc: 0.9817\nEpoch 15/40\n600/600 [==============================] - 7s 12ms/step - loss: 0.0623 - acc: 0.9817\nEpoch 16/40\n600/600 [==============================] - 7s 12ms/step - loss: 0.0511 - acc: 0.9883\nEpoch 17/40\n600/600 [==============================] - 7s 12ms/step - loss: 0.0525 - acc: 0.9833\nEpoch 18/40\n600/600 [==============================] - 7s 12ms/step - loss: 0.0471 - acc: 0.9883\nEpoch 19/40\n600/600 [==============================] - 7s 12ms/step - loss: 0.0496 - acc: 0.9867\nEpoch 20/40\n600/600 [==============================] - 8s 13ms/step - loss: 0.0577 - acc: 0.9867\nEpoch 21/40\n600/600 [==============================] - 7s 12ms/step - loss: 0.0442 - acc: 0.9917\nEpoch 22/40\n600/600 [==============================] - 7s 12ms/step - loss: 0.0407 - acc: 0.9883\nEpoch 23/40\n600/600 [==============================] - 7s 12ms/step - loss: 0.0566 - acc: 0.9800\nEpoch 24/40\n600/600 [==============================] - 8s 13ms/step - loss: 0.0392 - acc: 0.9900\nEpoch 25/40\n600/600 [==============================] - 7s 12ms/step - loss: 0.0308 - acc: 0.9933\nEpoch 26/40\n600/600 [==============================] - 8s 13ms/step - loss: 0.0362 - acc: 0.9883\nEpoch 27/40\n600/600 [==============================] - 7s 12ms/step - loss: 0.0337 - acc: 0.9900\nEpoch 28/40\n600/600 [==============================] - 7s 12ms/step - loss: 0.0319 - acc: 0.9917\nEpoch 29/40\n600/600 [==============================] - 7s 12ms/step - loss: 0.0281 - acc: 0.9950\nEpoch 30/40\n600/600 [==============================] - 7s 12ms/step - loss: 0.0260 - acc: 0.9917\nEpoch 31/40\n600/600 [==============================] - 7s 12ms/step - loss: 0.0268 - acc: 0.9917\nEpoch 32/40\n600/600 [==============================] - 7s 12ms/step - loss: 0.0214 - acc: 0.9950\nEpoch 33/40\n600/600 [==============================] - 7s 12ms/step - loss: 0.0215 - acc: 0.9950\nEpoch 34/40\n600/600 [==============================] - 7s 12ms/step - loss: 0.0174 - acc: 0.9983\nEpoch 35/40\n600/600 [==============================] - 7s 12ms/step - loss: 0.0194 - acc: 0.9950\nEpoch 36/40\n600/600 [==============================] - 7s 12ms/step - loss: 0.0151 - acc: 1.0000\nEpoch 37/40\n600/600 [==============================] - 7s 12ms/step - loss: 0.0152 - acc: 0.9967\nEpoch 38/40\n600/600 [==============================] - 7s 12ms/step - loss: 0.0132 - acc: 1.0000\nEpoch 39/40\n600/600 [==============================] - 7s 12ms/step - loss: 0.0175 - acc: 0.9967\nEpoch 40/40\n600/600 [==============================] - 7s 12ms/step - loss: 0.0143 - acc: 0.9950\n150/150 [==============================] - 1s 8ms/step\n误差值 = 0.11696695228417714\n准确度 = 0.9533333309491475\n"
    }
   ],
   "source": [
    "happy_model = HappyModel(X_train.shape[1:])\n",
    "happy_model.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\n",
    "happy_model.fit(X_train, Y_train, epochs=40, batch_size=50)\n",
    "preds = happy_model.evaluate(X_test, Y_test, batch_size=32)\n",
    "print(f'误差值 = {preds[0]}')\n",
    "print(f'准确度 = {preds[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         (None, 64, 64, 3)         0         \n_________________________________________________________________\nzero_padding2d_1 (ZeroPaddin (None, 70, 70, 3)         0         \n_________________________________________________________________\nconv0 (Conv2D)               (None, 64, 64, 32)        4736      \n_________________________________________________________________\nbn0 (BatchNormalization)     (None, 64, 64, 32)        128       \n_________________________________________________________________\nactivation_1 (Activation)    (None, 64, 64, 32)        0         \n_________________________________________________________________\nmax_pool (MaxPooling2D)      (None, 32, 32, 32)        0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 32768)             0         \n_________________________________________________________________\nfc (Dense)                   (None, 1)                 32769     \n=================================================================\nTotal params: 37,633\nTrainable params: 37,569\nNon-trainable params: 64\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "happy_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<svg height=\"556pt\" viewBox=\"0.00 0.00 225.00 556.00\" width=\"225pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 552)\">\n<title>G</title>\n<polygon fill=\"white\" points=\"-4,4 -4,-552 221,-552 221,4 -4,4\" stroke=\"none\"/>\n<!-- 2798615558352 -->\n<g class=\"node\" id=\"node1\"><title>2798615558352</title>\n<polygon fill=\"none\" points=\"45.5,-511.5 45.5,-547.5 171.5,-547.5 171.5,-511.5 45.5,-511.5\" stroke=\"black\"/>\n<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"108.5\" y=\"-525.8\">input_1: InputLayer</text>\n</g>\n<!-- 2798611842048 -->\n<g class=\"node\" id=\"node2\"><title>2798611842048</title>\n<polygon fill=\"none\" points=\"0,-438.5 0,-474.5 217,-474.5 217,-438.5 0,-438.5\" stroke=\"black\"/>\n<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"108.5\" y=\"-452.8\">zero_padding2d_1: ZeroPadding2D</text>\n</g>\n<!-- 2798615558352&#45;&gt;2798611842048 -->\n<g class=\"edge\" id=\"edge1\"><title>2798615558352-&gt;2798611842048</title>\n<path d=\"M108.5,-511.313C108.5,-503.289 108.5,-493.547 108.5,-484.569\" fill=\"none\" stroke=\"black\"/>\n<polygon fill=\"black\" points=\"112,-484.529 108.5,-474.529 105,-484.529 112,-484.529\" stroke=\"black\"/>\n</g>\n<!-- 2798505018536 -->\n<g class=\"node\" id=\"node3\"><title>2798505018536</title>\n<polygon fill=\"none\" points=\"56,-365.5 56,-401.5 161,-401.5 161,-365.5 56,-365.5\" stroke=\"black\"/>\n<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"108.5\" y=\"-379.8\">conv0: Conv2D</text>\n</g>\n<!-- 2798611842048&#45;&gt;2798505018536 -->\n<g class=\"edge\" id=\"edge2\"><title>2798611842048-&gt;2798505018536</title>\n<path d=\"M108.5,-438.313C108.5,-430.289 108.5,-420.547 108.5,-411.569\" fill=\"none\" stroke=\"black\"/>\n<polygon fill=\"black\" points=\"112,-411.529 108.5,-401.529 105,-411.529 112,-411.529\" stroke=\"black\"/>\n</g>\n<!-- 2798615583768 -->\n<g class=\"node\" id=\"node4\"><title>2798615583768</title>\n<polygon fill=\"none\" points=\"31.5,-292.5 31.5,-328.5 185.5,-328.5 185.5,-292.5 31.5,-292.5\" stroke=\"black\"/>\n<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"108.5\" y=\"-306.8\">bn0: BatchNormalization</text>\n</g>\n<!-- 2798505018536&#45;&gt;2798615583768 -->\n<g class=\"edge\" id=\"edge3\"><title>2798505018536-&gt;2798615583768</title>\n<path d=\"M108.5,-365.313C108.5,-357.289 108.5,-347.547 108.5,-338.569\" fill=\"none\" stroke=\"black\"/>\n<polygon fill=\"black\" points=\"112,-338.529 108.5,-328.529 105,-338.529 112,-338.529\" stroke=\"black\"/>\n</g>\n<!-- 2798614371520 -->\n<g class=\"node\" id=\"node5\"><title>2798614371520</title>\n<polygon fill=\"none\" points=\"34.5,-219.5 34.5,-255.5 182.5,-255.5 182.5,-219.5 34.5,-219.5\" stroke=\"black\"/>\n<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"108.5\" y=\"-233.8\">activation_1: Activation</text>\n</g>\n<!-- 2798615583768&#45;&gt;2798614371520 -->\n<g class=\"edge\" id=\"edge4\"><title>2798615583768-&gt;2798614371520</title>\n<path d=\"M108.5,-292.313C108.5,-284.289 108.5,-274.547 108.5,-265.569\" fill=\"none\" stroke=\"black\"/>\n<polygon fill=\"black\" points=\"112,-265.529 108.5,-255.529 105,-265.529 112,-265.529\" stroke=\"black\"/>\n</g>\n<!-- 2798613830008 -->\n<g class=\"node\" id=\"node6\"><title>2798613830008</title>\n<polygon fill=\"none\" points=\"26.5,-146.5 26.5,-182.5 190.5,-182.5 190.5,-146.5 26.5,-146.5\" stroke=\"black\"/>\n<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"108.5\" y=\"-160.8\">max_pool: MaxPooling2D</text>\n</g>\n<!-- 2798614371520&#45;&gt;2798613830008 -->\n<g class=\"edge\" id=\"edge5\"><title>2798614371520-&gt;2798613830008</title>\n<path d=\"M108.5,-219.313C108.5,-211.289 108.5,-201.547 108.5,-192.569\" fill=\"none\" stroke=\"black\"/>\n<polygon fill=\"black\" points=\"112,-192.529 108.5,-182.529 105,-192.529 112,-192.529\" stroke=\"black\"/>\n</g>\n<!-- 2798611294920 -->\n<g class=\"node\" id=\"node7\"><title>2798611294920</title>\n<polygon fill=\"none\" points=\"54,-73.5 54,-109.5 163,-109.5 163,-73.5 54,-73.5\" stroke=\"black\"/>\n<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"108.5\" y=\"-87.8\">flatten_1: Flatten</text>\n</g>\n<!-- 2798613830008&#45;&gt;2798611294920 -->\n<g class=\"edge\" id=\"edge6\"><title>2798613830008-&gt;2798611294920</title>\n<path d=\"M108.5,-146.313C108.5,-138.289 108.5,-128.547 108.5,-119.569\" fill=\"none\" stroke=\"black\"/>\n<polygon fill=\"black\" points=\"112,-119.529 108.5,-109.529 105,-119.529 112,-119.529\" stroke=\"black\"/>\n</g>\n<!-- 2798615584440 -->\n<g class=\"node\" id=\"node8\"><title>2798615584440</title>\n<polygon fill=\"none\" points=\"74,-0.5 74,-36.5 143,-36.5 143,-0.5 74,-0.5\" stroke=\"black\"/>\n<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"108.5\" y=\"-14.8\">fc: Dense</text>\n</g>\n<!-- 2798611294920&#45;&gt;2798615584440 -->\n<g class=\"edge\" id=\"edge7\"><title>2798611294920-&gt;2798615584440</title>\n<path d=\"M108.5,-73.3129C108.5,-65.2895 108.5,-55.5475 108.5,-46.5691\" fill=\"none\" stroke=\"black\"/>\n<polygon fill=\"black\" points=\"112,-46.5288 108.5,-36.5288 105,-46.5289 112,-46.5288\" stroke=\"black\"/>\n</g>\n</g>\n</svg>",
      "text/plain": "<IPython.core.display.SVG object>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_model(happy_model, to_file='happy_model.png')\n",
    "SVG(model_to_dot(happy_model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_block(X, f, filters, stage, block):\n",
    "    \n",
    "    '''\n",
    "    input:\n",
    "    X - tensor, input of the block, (samples, height, weight, channels)\n",
    "    f - int, size of filter\n",
    "    filters - list of int, list of filter numbers of every layer\n",
    "    stage - int, for layer name\n",
    "    block - str, for layer name\n",
    "\n",
    "    output:\n",
    "    X - output of the block, (samples, height, weight, channels)\n",
    "\n",
    "    '''\n",
    "\n",
    "    conv_name_base = f'{stage}_{block}__conv_branch__'\n",
    "    bn_name_base = f'{stage}_{block}__bn_branch__'\n",
    "\n",
    "    F1, F2, F3 = filters\n",
    "\n",
    "    X_shortcut = X\n",
    "\n",
    "    X = Conv2D(F1, (1, 1), name=f'{conv_name_base}main_1')(X)\n",
    "    X = BatchNormalization(axis=3, name=f'{bn_name_base}main_1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    X = Conv2D(F2, (f, f), padding='same', name=f'{conv_name_base}main_2')(X)\n",
    "    X = BatchNormalization(axis=3, name=f'{bn_name_base}main_2')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    X = Conv2D(F3, (1, 1), name=f'{conv_name_base}main_3')(X)\n",
    "    X = BatchNormalization(axis=3, name=f'{bn_name_base}main_3')(X)\n",
    "\n",
    "    X = layers.Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(X, f, s, filters, stage, block):\n",
    "        \n",
    "    '''\n",
    "    input:\n",
    "    X - tensor, input of the block, (samples, height, weight, channels)\n",
    "    f - int, size of filter\n",
    "    s - int, stride\n",
    "    filters - list of int, list of filter numbers of every layer\n",
    "    stage - int, for layer name\n",
    "    block - str, for layer name\n",
    "\n",
    "    output:\n",
    "    X - output of the block, (samples, height, weight, channels)\n",
    "    \n",
    "    '''\n",
    "\n",
    "    conv_name_base = f'{stage}_{block}__conv_branch__'\n",
    "    bn_name_base = f'{stage}_{block}__bn_branch__'\n",
    "\n",
    "    F1, F2, F3 = filters\n",
    "\n",
    "    X_shortcut = X\n",
    "\n",
    "    X = Conv2D(F1, (1, 1), strides=(s, s), name=f'{conv_name_base}main_1')(X)\n",
    "    X = BatchNormalization(axis=3, name=f'{bn_name_base}main_1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    X = Conv2D(F2, (f, f), padding='same', name=f'{conv_name_base}main_2')(X)\n",
    "    X = BatchNormalization(axis=3, name=f'{bn_name_base}main_2')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    X = Conv2D(F3, (1, 1), name=f'{conv_name_base}main_3')(X)\n",
    "    X = BatchNormalization(axis=3, name=f'{bn_name_base}main_3')(X)\n",
    "\n",
    "    X_shortcut = Conv2D(F3, (1, 1), strides=(s, s), name=f'{conv_name_base}short_1')(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis=3, name=f'{bn_name_base}short_1')(X_shortcut)\n",
    "\n",
    "    X = layers.Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myResNet50(input_shape=(64, 64, 3), classes=6):\n",
    "\n",
    "    '''\n",
    "    input_shape -  A shape tuple (integer), not including the batch size.\n",
    "        For instance, `shape=(32,)` indicates that the expected input\n",
    "        will be batches of 32-dimensional vectors.\n",
    "    '''\n",
    "\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    # stage1:\n",
    "    X = Conv2D(64, (7, 7), strides=(2, 2), padding='same', name='1__conv')(X_input)\n",
    "    X = BatchNormalization(axis=3, name='1__bn')(X)\n",
    "    X = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='1__max_pool')(X)\n",
    "\n",
    "    # stage2:\n",
    "    X = convolutional_block(X, 3, 1, [64, 64, 256], 2, 'a')\n",
    "    X = identify_block(X, 3, [64, 64, 256], 2, 'b')\n",
    "    X = identify_block(X, 3, [64, 64, 256], 2, 'c')\n",
    "\n",
    "    # stage3:\n",
    "    X = convolutional_block(X, 3, 2, [128, 128, 512], 3, 'a')\n",
    "    X = identify_block(X, 3, [128, 128, 512], 3, 'b')\n",
    "    X = identify_block(X, 3, [128, 128, 512], 3, 'c')\n",
    "    X = identify_block(X, 3, [128, 128, 512], 3, 'd')\n",
    "\n",
    "    # stage4:\n",
    "    X = convolutional_block(X, 3, 2, [256, 256, 1024], 4, 'a')\n",
    "    X = identify_block(X, 3, [256, 256, 1024], 4, 'b')\n",
    "    X = identify_block(X, 3, [256, 256, 1024], 4, 'c')\n",
    "    X = identify_block(X, 3, [256, 256, 1024], 4, 'd')\n",
    "    X = identify_block(X, 3, [256, 256, 1024], 4, 'e')\n",
    "    X = identify_block(X, 3, [256, 256, 1024], 4, 'f')\n",
    "\n",
    "    # stage5:\n",
    "    X = convolutional_block(X, 3, 2, [512, 512, 2048], 5, 'a')\n",
    "    X = identify_block(X, 3, [256, 256, 2048], 5, 'b')\n",
    "    X = identify_block(X, 3, [256, 256, 2048], 5, 'c')\n",
    "\n",
    "    # stage6:\n",
    "    X = AveragePooling2D(name='6__avg_pool')(X)\n",
    "    X = Flatten(name='6__flatten')(X)\n",
    "    X = Dense(classes, activation='softmax', name=f'6__fc_to{classes}')(X)\n",
    "\n",
    "    model = Model(inputs=X_input, outputs=X, name='myResNet50')\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel = myResNet50()\n",
    "mymodel.compile('adam', 'categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(mymodel, to_file='mymodel.png')\n",
    "#SVG(model_to_dot(mymodel).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import resnets_utils\n",
    "\n",
    "train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes = resnets_utils.load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "X_train.shape = (1080, 64, 64, 3)\nY_train.shape = (1080, 6)\nX_test.shape = (120, 64, 64, 3)\nY_test.shape = (120, 6)\n"
    }
   ],
   "source": [
    "X_train = train_set_x_orig / 255.\n",
    "X_test = test_set_x_orig / 255.\n",
    "Y_train = resnets_utils.convert_to_one_hot(train_set_y_orig, len(classes)).T\n",
    "Y_test = resnets_utils.convert_to_one_hot(test_set_y_orig, len(classes)).T\n",
    "print(f'X_train.shape = {X_train.shape}')\n",
    "print(f'Y_train.shape = {Y_train.shape}')\n",
    "print(f'X_test.shape = {X_test.shape}')\n",
    "print(f'Y_test.shape = {Y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "WARNING:tensorflow:From C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.where in 2.0, which has the same broadcast rule as np.where\nEpoch 1/10\n1080/1080 [==============================] - 162s 150ms/step - loss: 1.7030 - acc: 0.4417\nEpoch 2/10\n1080/1080 [==============================] - 136s 126ms/step - loss: 0.6558 - acc: 0.7815\nEpoch 3/10\n1080/1080 [==============================] - 128s 118ms/step - loss: 0.3066 - acc: 0.9009\nEpoch 4/10\n1080/1080 [==============================] - 127s 118ms/step - loss: 0.2658 - acc: 0.9148\nEpoch 5/10\n1080/1080 [==============================] - 127s 118ms/step - loss: 0.2527 - acc: 0.9333\nEpoch 6/10\n1080/1080 [==============================] - 127s 117ms/step - loss: 0.3486 - acc: 0.9037\nEpoch 7/10\n1080/1080 [==============================] - 127s 118ms/step - loss: 0.2028 - acc: 0.9333\nEpoch 8/10\n1080/1080 [==============================] - 128s 118ms/step - loss: 0.0844 - acc: 0.9731\nEpoch 9/10\n1080/1080 [==============================] - 127s 117ms/step - loss: 0.1117 - acc: 0.9685\nEpoch 10/10\n1080/1080 [==============================] - 127s 117ms/step - loss: 0.0986 - acc: 0.9593\n"
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x2c135514a58>"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mymodel.fit(X_train, Y_train, batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "120/120 [==============================] - 8s 70ms/step\n误差值 = 3.369066572189331\n准确度 = 0.5583333373069763\n"
    }
   ],
   "source": [
    "predicts = mymodel.evaluate(X_test, Y_test, batch_size=32)\n",
    "print(f'误差值 = {predicts[0]}')\n",
    "print(f'准确度 = {predicts[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0 0.16666666666666666\n1 0.16666666666666666\n2 0.16666666666666666\n3 0.16666666666666666\n4 0.16666666666666666\n5 0.16666666666666666\n"
    }
   ],
   "source": [
    "print(0, np.mean(np.squeeze(test_set_y_orig) == 0))\n",
    "print(1, np.mean(np.squeeze(test_set_y_orig) == 1))\n",
    "print(2, np.mean(np.squeeze(test_set_y_orig) == 2))\n",
    "print(3, np.mean(np.squeeze(test_set_y_orig) == 3))\n",
    "print(4, np.mean(np.squeeze(test_set_y_orig) == 4))\n",
    "print(5, np.mean(np.squeeze(test_set_y_orig) == 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}